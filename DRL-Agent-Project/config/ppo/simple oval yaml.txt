behaviors:
  ArcadeDriver:
    trainer_type: ppo
    hyperparameters:
      batch_size: 2048         
      buffer_size: 20480       
      learning_rate: 3.0e-4     
      beta: 1.5e-3              # INCREASED: More exploration for complex reward structure
      epsilon: 0.2   
      lambd: 0.95              
      num_epoch: 3            
      learning_rate_schedule: linear
    network_settings:
      normalize: true        
      hidden_units: 256         
      num_layers: 3           
      vis_encode_type: simple 
    reward_signals:
      extrinsic:
        gamma: 0.995             # INCREASED: Better long-term reward learning
        strength: 1.0
    keep_checkpoints: 10        
    checkpoint_interval: 25000  
    max_steps: 10000000          # INCREASED: More time to learn complex behaviors
    summary_freq: 5000         
    time_horizon: 3000          # INCREASED: Allow longer episodes for lap completion
    threaded: false

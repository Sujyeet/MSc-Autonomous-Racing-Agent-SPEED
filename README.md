# MSc Autonomous Racing Agent SPEED

## Project Overview

This repository contains the comprehensive implementation and research for an MSc project focused on developing and comparing autonomous racing agents. The project explores both traditional heuristic approaches and modern Deep Reinforcement Learning (DRL) techniques for autonomous vehicle control in racing environments.

## ğŸ Research Objectives

- **Primary Goal**: Develop and compare autonomous racing agents using heuristic and DRL approaches
- **Performance Analysis**: Evaluate agents across multiple metrics including speed, safety, and adaptability
- **Comparative Study**: Analyze the trade-offs between interpretable heuristic methods and learning-based approaches
- **Real-world Applications**: Investigate scalability and practical deployment considerations

## ğŸ—ï¸ Project Structure

```
MSc-Autonomous-Racing-Agent-SPEED/
â”œâ”€â”€ ğŸ“ Heuristic-Agent-Project/          # Traditional rule-based agent implementation
â”‚   â”œâ”€â”€ README-Heuristic.md             # Heuristic agent documentation
â”‚   â”œâ”€â”€ src/                             # Source code for heuristic algorithms
â”‚   â”œâ”€â”€ config/                          # Configuration files
â”‚   â””â”€â”€ tests/                           # Unit tests
â”‚
â”œâ”€â”€ ğŸ“ DRL-Agent-Project/                # Deep Reinforcement Learning agent
â”‚   â”œâ”€â”€ README-DRL.md                    # DRL agent documentation
â”‚   â”œâ”€â”€ src/                             # Neural network implementations
â”‚   â”œâ”€â”€ training/                        # Training scripts and utilities
â”‚   â”œâ”€â”€ Trained-Models/                  # Saved model weights and checkpoints
â”‚   â”‚   â””â”€â”€ .gitkeep                     # Ensures directory tracking
â”‚   â””â”€â”€ evaluation/                      # Model evaluation scripts
â”‚
â”œâ”€â”€ ğŸ“ Documentation/                    # Project documentation
â”‚   â”œâ”€â”€ Setup-Instructions.md           # Installation and setup guide
â”‚   â”œâ”€â”€ API-Reference.md                 # Code documentation
â”‚   â”œâ”€â”€ Research-Methods.md             # Methodology documentation
â”‚   â””â”€â”€ User-Guide.md                   # Usage instructions
â”‚
â”œâ”€â”€ ğŸ“ Results-and-Analysis/             # Experimental results and analysis
â”‚   â”œâ”€â”€ README.md                        # Analysis documentation
â”‚   â”œâ”€â”€ Performance-Metrics/             # Quantitative results
â”‚   â”œâ”€â”€ Comparison-Studies/              # Comparative analysis
â”‚   â”œâ”€â”€ Visualizations/                  # Plots and charts
â”‚   â””â”€â”€ Statistical-Analysis/            # Statistical tests and analysis
â”‚
â”œâ”€â”€ ğŸ“„ .gitignore                        # Git ignore file
â”œâ”€â”€ ğŸ“„ README.md                         # This file
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Python dependencies
â”œâ”€â”€ ğŸ“„ setup.py                          # Package installation script
â””â”€â”€ ğŸ“„ LICENSE                           # License information
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git
- CUDA-capable GPU (recommended for DRL training)

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/Sujyeet/MSc-Autonomous-Racing-Agent-SPEED.git
   cd MSc-Autonomous-Racing-Agent-SPEED
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Follow detailed setup instructions**:
   See [`Documentation/Setup-Instructions.md`](Documentation/Setup-Instructions.md) for complete setup guide.

## ğŸ§  Agent Implementations

### Heuristic Agent
- **Path Planning**: A* algorithm with dynamic obstacle avoidance
- **Speed Control**: PID controllers optimized for racing scenarios
- **Decision Making**: Rule-based system with safety prioritization
- **Advantages**: Interpretable, fast execution, predictable behavior

### DRL Agent
- **Algorithms**: DQN, PPO, SAC implementations
- **Neural Architecture**: Custom CNN-LSTM networks for temporal reasoning
- **Training Environment**: Custom racing simulator with realistic physics
- **Advantages**: Adaptive learning, complex strategy development

## ğŸ“Š Performance Metrics

### Primary Metrics
- **Lap Time**: Average and best performance across tracks
- **Success Rate**: Percentage of completed laps without incidents
- **Safety Score**: Collision avoidance and track boundary adherence
- **Efficiency**: Computational resource utilization

### Evaluation Tracks
- Multiple track configurations (oval, road course, street circuit)
- Varying weather and lighting conditions
- Different traffic and obstacle scenarios

## ğŸ”¬ Research Methodology

1. **Literature Review**: Comprehensive analysis of existing approaches
2. **Implementation**: Development of both agent types with comparable interfaces
3. **Experimentation**: Systematic testing across multiple scenarios
4. **Statistical Analysis**: Rigorous comparison using appropriate statistical tests
5. **Validation**: Cross-validation and generalization testing

## ğŸ“ˆ Key Findings

*[This section will be populated as research progresses]*

### Preliminary Results
- Heuristic agents show consistent performance with lower variance
- DRL agents demonstrate superior adaptability to new environments
- Trade-offs observed between interpretability and performance
- Computational requirements vary significantly between approaches

## ğŸ› ï¸ Technology Stack

### Core Technologies
- **Python 3.8+**: Primary programming language
- **PyTorch/TensorFlow**: Deep learning frameworks
- **OpenAI Gym**: Reinforcement learning environment interface
- **NumPy/SciPy**: Numerical computing and analysis
- **Matplotlib/Seaborn**: Data visualization

### Racing Simulation
- **Physics Engine**: Custom integration with realistic vehicle dynamics
- **Rendering**: OpenGL-based visualization
- **Sensors**: Simulated LIDAR, cameras, and IMU data

## ğŸ“‹ Usage Examples

### Running Heuristic Agent
```bash
cd Heuristic-Agent-Project/
python src/main.py --track oval --config config/default.yaml
```

### Training DRL Agent
```bash
cd DRL-Agent-Project/
python training/train_dqn.py --env racing-v1 --episodes 10000
```

### Comparing Agents
```bash
python Results-and-Analysis/compare_agents.py --agents heuristic,drl --trials 100
```

## ğŸ¤ Contributing

This is an academic research project. For collaboration or questions:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/research-enhancement`)
3. Commit changes (`git commit -am 'Add new analysis method'`)
4. Push to branch (`git push origin feature/research-enhancement`)
5. Create Pull Request

## ğŸ“š Publications and Documentation

- **Research Paper**: [Link to published paper]
- **Conference Presentations**: [Links to presentations]
- **Technical Documentation**: Available in [`Documentation/`](Documentation/) folder
- **API Reference**: Generated from source code documentation

## ğŸ† Acknowledgments

- Academic supervisors and research committee
- Open-source communities for frameworks and tools
- Racing simulation software providers
- Research participants and collaborators

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Contact

- **Author**: Sujyeet
- **Institution**: [University Name]
- **Email**: [Contact Email]
- **Project Duration**: [Start Date] - [End Date]

## ğŸ”— Related Work

- [Link to related research papers]
- [References to competing approaches]
- [Citations and acknowledgments]

---

**Note**: This repository represents ongoing research. Results, methodologies, and implementations are subject to updates as the research progresses.

**Last Updated**: August 2025
